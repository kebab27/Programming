{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNz1C+s0vMxS6l2p6hMmBrG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kebab27/Programming/blob/main/IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "x6upWaHH_300",
        "outputId": "e86d8876-f176-432e-e4f7-b2f8766bed62"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    movies = scrape_movie_data()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "def scrape_movie_data():\n",
        "    base_url = \"https://www.imdb.com/chart/top\"\n",
        "    response = requests.get(base_url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        movie_data = []\n",
        "        for movie in soup.select(\"td.titleColumn\"):\n",
        "            title = movie.find(\"a\").get_text()\n",
        "            year = int(movie.find(\"span\").get_text()[1:-1])\n",
        "            rating = float(movie.find_next(\"td\", class_=\"ratingColumn imdbRating\").strong.get_text())\n",
        "            movie_data.append({'title': title, 'year': year, 'rating': rating})\n",
        "        return movie_data\n",
        "    else:\n",
        "        print(\"Failed to retrieve data from IMDb.\")\n",
        "        return None\n",
        "\n",
        "      movies = scrape_movie_data()\n",
        "\n",
        "      #Data Preprocessing and Feature Extraction\n",
        "\n",
        "      import pandas as pd\n",
        "def preprocess_and_extract_features(movie_data):\n",
        "    # Create a DataFrame from the scraped data\n",
        "    df = pd.DataFrame(movie_data)\n",
        "\n",
        "    df['genres'] = ['Action, Adventure', 'Drama', 'Action, Adventure, Sci-Fi', 'Crime, Drama, Thriller', ...]\n",
        "    df['runtime'] = [142, 195, 148, 175, ...]\n",
        "\n",
        "    return df\n",
        "\n",
        "movies_df = preprocess_and_extract_features(movies)\n",
        "\n",
        "#Loading Data into SQLite Database\n",
        "\n",
        "import sqlite3\n",
        "\n",
        "def create_database(database_name):\n",
        "    conn = sqlite3.connect(database_name)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    cursor.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS movies (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            title TEXT NOT NULL,\n",
        "            year INTEGER NOT NULL,\n",
        "            rating REAL NOT NULL,\n",
        "            genres TEXT NOT NULL,\n",
        "            runtime INTEGER NOT NULL\n",
        "        );\n",
        "    ''')\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def insert_data_to_database(dataframe, database_name):\n",
        "    conn = sqlite3.connect(database_name)\n",
        "    dataframe.to_sql('movies', conn, if_exists='append', index=False)\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "database_name = 'movie_database.db'\n",
        "create_database(database_name)\n",
        "insert_data_to_database(movies_df, database_name)\n",
        "\n",
        "#Data Analysis and Answering Questions\n",
        "\n",
        "def perform_data_analysis(database_name):\n",
        "    conn = sqlite3.connect(database_name)\n",
        "\n",
        "\n",
        "    query = '''\n",
        "        SELECT title, year, rating\n",
        "        FROM movies\n",
        "        ORDER BY rating DESC\n",
        "        LIMIT 10;\n",
        "    '''\n",
        "    top_rated_movies = pd.read_sql_query(query, conn)\n",
        "    conn.close()\n",
        "\n",
        "    return top_rated_movies\n",
        "\n",
        "\n",
        "top_10_movies = perform_data_analysis(database_name)\n",
        "print(top_10_movies)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this data pipeline project, I will create a pipeline to analyze movie data. We will use web scraping to acquire movie information from a movie database (IMDb), preprocess the data, extract relevant features, and store it in a SQLite database. We'll then perform some data analysis on the dataset to answer questions of interest related to the movies.\n",
        "\n",
        "Python libraries used in this project:\n",
        "\n",
        "Requests: To make HTTP requests to IMDb website for web scraping.\n",
        "BeautifulSoup: For parsing the HTML content and extracting relevant data from web pages.\n",
        "Pandas: For data manipulation and analysis.\n",
        "SQLite3: For creating and managing the database.\n",
        "Assumptions:\n",
        "\n",
        "We are interested in movies released up to the knowledge cutoff date (September 2021).\n",
        "We will focus on data related to movie titles, release years, IMDb ratings, genres, and runtime.\n",
        "\n",
        "\n",
        "In this pipeline, we acquired movie data by web scraping IMDb's top-rated movies, extracted relevant features (genres and runtime) using placeholder data (replace with actual API calls in practice), and loaded the data into an SQLite database. Finally, we performed data analysis to get the top 10 highest-rated movies."
      ],
      "metadata": {
        "id": "KDTaNP-IA8Iv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q036rRQZBF7s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZAzswBumBHEV"
      }
    }
  ]
}